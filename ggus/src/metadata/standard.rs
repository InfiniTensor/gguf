pub const DEFAULT_ALIGNMENT: usize = 32;
meta_kv_macro::meta_kvs! {
// general.required
 str  "general.architecture"
 u32  "general.quantization_version"
 u32  "general.alignment"
// general
 str  "general.name"
 str  "general.author"
 str  "general.version"
 str  "general.organization"
 str  "general.basename"
 str  "general.finetune"
 str  "general.decription"
 str  "general.quantized_by"
 str  "general.size_label"
 str  "general.license.name"
 str  "general.license.link"
 str  "general.url"
 str  "general.doi"
 str  "general.uuid"
 str  "general.repo_url"
[str] "general.tags"
[str] "general.languages"
[str] "general.datasets"
 u32  "general.file_type"
// general.source
 str  "general.source.url"
 str  "general.source.doi"
 str  "general.source.uuid"
 str  "general.source.repo_url"
 u32  "general.base_model.count"
 str  "general.base_model.{id}.name"
 str  "general.base_model.{id}.author"
 str  "general.base_model.{id}.version"
 str  "general.base_model.{id}.organization"
 str  "general.base_model.{id}.url"
 str  "general.base_model.{id}.doi"
 str  "general.base_model.{id}.uuid"
 str  "general.base_model.{id}.repo_url"
// llm
 u64  "{llm}.context_length"
 u64  "{llm}.embedding_length"
 u64  "{llm}.block_count"
 u64  "{llm}.feed_forward_length"
 bool "{llm}.use_parallel_residual"
 str  "{llm}.tensor_data_layout"
 u32  "{llm}.expert_count"
 u32  "{llm}.expert_used_count"
// llm.attention
 u64  "{llm}.attention.head_count"
 u64  "{llm}.attention.head_count_kv"
 f32  "{llm}.attention.max_alibi_bias"
 f32  "{llm}.attention.clamp_kqv"
 f32  "{llm}.attention.layer_norm_epsilon"
 f32  "{llm}.attention.layer_norm_rms_epsilon"
 u32  "{llm}.attention.key_length"
 u32  "{llm}.attention.value_length"
// llm.rope
 u64  "{llm}.rope.dimension_count"
 f32  "{llm}.rope.freq_base"
// llm.rope.scaling
 str  "{llm}.rope.scaling.type"
 f32  "{llm}.rope.scaling.factor"
 u32  "{llm}.rope.scaling.original_context_length"
 bool "{llm}.rope.scaling.finetuned"
 f32  "{llm}.rope.scaling.scale_linear"
// llm.ssm
 u32  "{llm}.ssm.conv_kernel"
 u32  "{llm}.ssm.inner_size"
 u32  "{llm}.ssm.state_size"
 u32  "{llm}.ssm.time_step_rank"
// tokenizer.ggml
 str  "tokenizer.ggml.model"
[str] "tokenizer.ggml.tokens"
[f32] "tokenizer.ggml.scores"
[i32] "tokenizer.ggml.token_type"
[str] "tokenizer.ggml.merges"
[str] "tokenizer.ggml.added_tokens"
// tokenizer.ggml.special-tokens
 u32  "tokenizer.ggml.bos_token_id"
 u32  "tokenizer.ggml.eos_token_id"
 u32  "tokenizer.ggml.unknown_token_id"
 u32  "tokenizer.ggml.separator_token_id"
 u32  "tokenizer.ggml.padding_token_id"
// tokenizer.huggingface
 str  "tokenizer.huggingface.json"
// tokenizer.other
 str  "tokenizer.rwkv.world"
 str  "tokenizer.chat_template"
}
